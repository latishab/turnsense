{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-processing Multi-turn Dialogues from MultiWOZ2.2**\n",
        "\n",
        "In this section, we preprocess the MultiWOZ 2.2 dataset for End-of-Utterance (EOU) detection. The steps are as follows:\n",
        "\n",
        "1. Extracting Context: We extract the last 3 turns of each dialogue (user, assistant, user) as the context.\n",
        "2. Formatting Data: The dialogues are restructured into a JSON format containing context (dialogue turns) and a label (1 for EOU, 0 for non-EOU).\n",
        "3. Dataset Splitting: The dataset is split into two parts: a training set (dataset_train.json) and a test set (dataset_test.json).\n"
      ],
      "metadata": {
        "id": "cZq_tS5JTf-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj9svFlmMBTE",
        "outputId": "a3f7bf64-2338-49fc-aaaf-153ba8b18ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'README.md', '.ipynb_checkpoints', 'dialog_acts.json', 'dataset_test.json', 'train', 'multiwoz_output.json', 'dataset_train.json', 'test', 'schema.json', 'requirements.txt', 'dev', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"/content\"))  # This will list all files in the /content directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pVG3WPHaB2Zv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Handle extracting relevant dialogue context from the data\n",
        "def extract_dialogue_context(dialogue_data):\n",
        "    formatted_data = []\n",
        "\n",
        "    # Iterate through each dialogue\n",
        "    for dialogue_info in dialogue_data:\n",
        "        # Extract dialogue turns safely with a fallback in case 'turns' is missing\n",
        "        dialogue_turns = dialogue_info.get(\"turns\", [])\n",
        "        if not dialogue_turns:\n",
        "            print(f\"Warning: 'turns' field is missing or empty in dialogue: {dialogue_info.get('dialogue_id', 'Unknown')}\")\n",
        "\n",
        "        dialogue_context = []\n",
        "        label = 0  # Default label is 0, can be manually annotated later\n",
        "\n",
        "        # We only need the first 3 turns (User, Assistant, User)\n",
        "        # Process the first 3 turns in the dialogue\n",
        "        for i, turn in enumerate(dialogue_turns[:3]):\n",
        "            speaker = turn.get(\"speaker\", \"\")\n",
        "            utterance = turn.get(\"utterance\", \"\")\n",
        "\n",
        "            # Safely append the user/system utterances to the context\n",
        "            if speaker == \"USER\":\n",
        "                dialogue_context.append({\"role\": \"user\", \"content\": utterance})\n",
        "            elif speaker == \"SYSTEM\":\n",
        "                dialogue_context.append({\"role\": \"assistant\", \"content\": utterance})\n",
        "\n",
        "            # Check for End of Utterance (EOU) based on some dialogue act signals (e.g., \"general-bye\")\n",
        "            frames = turn.get(\"frames\", [])\n",
        "\n",
        "            # Check if frames is non-empty and then check for 'actions'\n",
        "            if frames:\n",
        "                dialog_act = frames[0].get(\"actions\", [])\n",
        "                if any(\"general-bye\" in action for action in dialog_act):\n",
        "                    label = 1  # EOU detected\n",
        "\n",
        "        # After processing the dialogue turns, store the context and label\n",
        "        if dialogue_context:\n",
        "            formatted_data.append({\n",
        "                \"context\": dialogue_context,\n",
        "                \"label\": label  # Initially set as 0, you can change it later\n",
        "            })\n",
        "\n",
        "    return formatted_data\n",
        "\n",
        "def main():\n",
        "    # Directories containing the dialogue JSON files for training and testing\n",
        "    train_folder = '/content/train'\n",
        "    test_folder = '/content/test'\n",
        "\n",
        "    # Separate lists for train and test data\n",
        "    train_data = []\n",
        "    test_data = []\n",
        "\n",
        "    # Process training data (dialogues_001.json to dialogues_017.json)\n",
        "    for i in range(1, 18):  # From 001 to 017\n",
        "        dialogue_file = os.path.join(train_folder, f'dialogues_{i:03d}.json')  # Format with leading zeros\n",
        "\n",
        "        # Check if the file exists\n",
        "        if os.path.exists(dialogue_file):\n",
        "            with open(dialogue_file, \"r\") as f:\n",
        "                dialogue_data = json.load(f)\n",
        "\n",
        "            # Extract dialogue context for each file\n",
        "            train_data.extend(extract_dialogue_context(dialogue_data))\n",
        "        else:\n",
        "            print(f\"File {dialogue_file} not found.\")\n",
        "\n",
        "    # Process testing data (dialogues_xxx.json in /content/test folder)\n",
        "    for filename in os.listdir(test_folder):\n",
        "        if filename.startswith(\"dialogues_\") and filename.endswith(\".json\"):\n",
        "            dialogue_file = os.path.join(test_folder, filename)\n",
        "\n",
        "            # Check if the file exists\n",
        "            if os.path.exists(dialogue_file):\n",
        "                with open(dialogue_file, \"r\") as f:\n",
        "                    dialogue_data = json.load(f)\n",
        "\n",
        "                # Extract dialogue context for each file\n",
        "                test_data.extend(extract_dialogue_context(dialogue_data))\n",
        "            else:\n",
        "                print(f\"File {dialogue_file} not found.\")\n",
        "\n",
        "    # Save the results to dataset_train.json\n",
        "    train_dataset_path = '/content/dataset_train.json'\n",
        "    with open(train_dataset_path, 'w') as f:\n",
        "        json.dump(train_data, f, indent=2)\n",
        "\n",
        "    # Save the results to dataset_test.json\n",
        "    test_dataset_path = '/content/dataset_test.json'\n",
        "    with open(test_dataset_path, 'w') as f:\n",
        "        json.dump(test_data, f, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Printing Our Dataset**"
      ],
      "metadata": {
        "id": "tv0mbEGITYrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the dataset.json file\n",
        "dataset_path = '/content/dataset_train.json'\n",
        "with open(dataset_path, 'r') as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "# Print the total number of entries\n",
        "print(f\"Total entries in the training dataset: {len(dataset)}\")\n",
        "\n",
        "# Load the dataset.json file\n",
        "dataset_path = '/content/dataset_test.json'\n",
        "with open(dataset_path, 'r') as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "# Print the total number of entries\n",
        "print(f\"Total entries in the test dataset: {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muV_q1P8TptQ",
        "outputId": "d54241d7-1d37-4841-d8d3-9fff9dc7d6ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total entries in the training dataset: 8437\n",
            "Total entries in the test dataset: 1000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}